{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Goal:\n",
    " '<START>',\n",
    " 'row', 'btn', 'switch',\n",
    " 'row', 'radio',\n",
    " 'row', 'label','slider','label',\n",
    " 'row', 'switch',\n",
    " 'row', 'switch','switch','btn',\n",
    " 'row', 'btn', 'btn',\n",
    " 'row', 'check',\n",
    " 'footer', 'btn-dashboard','btn-dashboard','btn-home',\n",
    " '<END>',\n",
    " Tengo que:\n",
    "    -_probar que pasa con el voc_\n",
    "    -cambiar el compilador y ver si tiene sentido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.Vocabulary import *\n",
    "from classes.Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['<START>', 'row', 'radio', 'row', 'switch', 'switch', 'row', 'switch', 'footer', 'btn-search', 'btn-home', 'btn-search', '<END>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['<START>', 'row', 'radio', 'row', 'switch', 'switch', 'row','row','footer', 'btn-search', '<END>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>', 'stack', '{', '\\n']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = []\n",
    "b.append('<START>')\n",
    "b.append('stack')\n",
    "b.append('{')\n",
    "b.append('\\n')\n",
    "b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['row',\n",
       " 'radio',\n",
       " 'row',\n",
       " 'switch',\n",
       " 'switch',\n",
       " 'row',\n",
       " 'row',\n",
       " 'footer',\n",
       " 'btn-search',\n",
       " '<END>']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a[1:]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entra\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'stack',\n",
       " '{',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'radio',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'switch',\n",
       " ',',\n",
       " 'switch',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'footer',\n",
       " '{',\n",
       " '\\n',\n",
       " 'btn-search',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " '<END>']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = True\n",
    "\n",
    "for idx,token in enumerate(a):\n",
    "    if first_row:\n",
    "        print('entra')\n",
    "        first_row = False\n",
    "        if token == 'row':\n",
    "            b.append('row')\n",
    "            b.append('{')\n",
    "            b.append('\\n')\n",
    "        elif token == '<END>':\n",
    "            b.append('}')\n",
    "            b.append('\\n')\n",
    "            b.append('<END>')\n",
    "        else:\n",
    "            b.append('}')\n",
    "            b.append('\\n')\n",
    "            b.append('footer')\n",
    "            b.append('{')\n",
    "            b.append('\\n')\n",
    "            \n",
    "    else:\n",
    "        if token == 'row':\n",
    "            b.append('}')\n",
    "            b.append('\\n')\n",
    "            b.append('row')\n",
    "            b.append('{')\n",
    "            b.append('\\n')\n",
    "        elif token == 'footer':\n",
    "            b.append('}')\n",
    "            b.append('\\n')\n",
    "            b.append('}')\n",
    "            b.append('\\n')\n",
    "            b.append('footer')\n",
    "            b.append('{')\n",
    "            b.append('\\n')\n",
    "        elif token == '<END>':\n",
    "            b.append('\\n')\n",
    "            b.append('}')\n",
    "            b.append('\\n')\n",
    "            b.append('<END>')\n",
    "        else:\n",
    "            b.append(token)\n",
    "            if a[idx+1] != 'row' and a[idx+1] != 'footer' and a[idx+1] != '<END>':\n",
    "                b.append(',')\n",
    "            else:\n",
    "                b.append('\\n')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store captions and image names in vectors\n",
    "# Preprocess the images && Preprocess and tokenize the captions\n",
    "\n",
    "input_path = '../datasets/android/training_features'\n",
    "output_path = '../bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'stack',\n",
       " '{',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'radio',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'switch',\n",
       " ',',\n",
       " 'switch',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'switch',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'switch',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'row',\n",
       " '{',\n",
       " '\\n',\n",
       " 'switch',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " 'footer',\n",
       " '{',\n",
       " '\\n',\n",
       " 'btn-search',\n",
       " ',',\n",
       " 'btn-home',\n",
       " ',',\n",
       " 'btn-search',\n",
       " '\\n',\n",
       " '}',\n",
       " '\\n',\n",
       " '<END>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../datasets/android/eval_set'\n",
    "f = '202C4FD3-C429-48C3-B19A-50B0DF70EACB.gui'\n",
    "gui = open(\"{}/{}\".format(path, f), 'r')\n",
    "token_sequence = [START_TOKEN]\n",
    "for line in gui:\n",
    "    line = line.replace(\",\", \" ,\").replace(\"\\n\", \" \\n\")\n",
    "    tokens = line.split(\" \")\n",
    "    for token in tokens:\n",
    "        token_sequence.append(token)\n",
    "token_sequence.append(END_TOKEN)\n",
    "token_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sequence(token_sequence):\n",
    "    new_sequence = [ x for x in token_sequence if x is not '\\n']\n",
    "    sequence_no_comas = [ x for x in new_sequence if x is not ',']\n",
    "    sequence_no_arrows = [ x for x in sequence_no_comas if x is not '{']\n",
    "    sequence_no_arrows = [ x for x in sequence_no_arrows if x is not '}']\n",
    "    del sequence_no_arrows[1]\n",
    "    return sequence_no_arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_sequence(token_sequence):\n",
    "    first_row = True\n",
    "    a = token_sequence[1:]\n",
    "    b = []\n",
    "    b.append('<START>')\n",
    "    b.append('stack')\n",
    "    b.append('{')\n",
    "    b.append('\\n')\n",
    "    for idx,token in enumerate(a):\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            if token == 'row':\n",
    "                b.append('row')\n",
    "                b.append('{')\n",
    "                b.append('\\n')\n",
    "            elif token == '<END>':\n",
    "                b.append('}')\n",
    "                b.append('\\n')\n",
    "                b.append('<END>')\n",
    "            else:\n",
    "                b.append('}')\n",
    "                b.append('\\n')\n",
    "                b.append('footer')\n",
    "                b.append('{')\n",
    "                b.append('\\n')\n",
    "\n",
    "        else:\n",
    "            if token == 'row':\n",
    "                b.append('}')\n",
    "                b.append('\\n')\n",
    "                b.append('row')\n",
    "                b.append('{')\n",
    "                b.append('\\n')\n",
    "            elif token == 'footer':\n",
    "                b.append('}')\n",
    "                b.append('\\n')\n",
    "                b.append('}')\n",
    "                b.append('\\n')\n",
    "                b.append('footer')\n",
    "                b.append('{')\n",
    "                b.append('\\n')\n",
    "            elif token == '<END>':\n",
    "                b.append('}')\n",
    "                b.append('\\n')\n",
    "                b.append('<END>')\n",
    "            else:\n",
    "                b.append(token)\n",
    "                if a[idx+1] != 'row' and a[idx+1] != 'footer' and a[idx+1] != '<END>':\n",
    "                    b.append(',')\n",
    "                else:\n",
    "                    b.append('\\n')\n",
    "    return b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self):\n",
    "        self.input_shape = None\n",
    "        self.output_size = None\n",
    "\n",
    "        self.ids = []\n",
    "        self.input_images = []\n",
    "        self.total_sequences = []\n",
    "        \n",
    "        self.voc = Vocabulary()\n",
    "        self.size = 0\n",
    "    def load(self, path, generate_binary_sequences=False):\n",
    "        print(\"Loading data...\")\n",
    "        for f in os.listdir(path):\n",
    "            if f.find(\".gui\") != -1:\n",
    "                gui = open(\"{}/{}\".format(path, f), 'r')\n",
    "                file_name = f[:f.find(\".gui\")]\n",
    "\n",
    "                if os.path.isfile(\"{}/{}.png\".format(path, file_name)):\n",
    "                    img = Utils.get_preprocessed_img(\"{}/{}.png\".format(path, file_name), IMAGE_SIZE)\n",
    "                    self.append(file_name, gui, img)\n",
    "                elif os.path.isfile(\"{}/{}.npz\".format(path, file_name)):\n",
    "                    img = np.load(\"{}/{}.npz\".format(path, file_name))[\"features\"]\n",
    "                    self.append(file_name, gui, img)\n",
    "\n",
    "        print(\"Generating sparse vectors...\")\n",
    "        self.voc.create_binary_representation()\n",
    "        if generate_binary_sequences:\n",
    "            self.total_sequences = self.binarize(self.total_sequences, self.voc)\n",
    "        else:\n",
    "            self.total_sequences = self.indexify(self.total_sequences, self.voc)\n",
    "        \n",
    "        self.size = len(self.ids)\n",
    "        assert self.size == len(self.input_images) == len(self.total_sequences)\n",
    "        assert self.voc.size == len(self.voc.vocabulary)\n",
    "        \n",
    "        self.voc.save(output_path)\n",
    "        \n",
    "        print(\"Dataset size: {}\".format(self.size))\n",
    "        print(\"Vocabulary size: {}\".format(self.voc.size))\n",
    "\n",
    "        self.input_shape = self.input_images[0].shape\n",
    "        self.output_size = self.voc.size\n",
    "\n",
    "        print(\"Input shape: {}\".format(self.input_shape))\n",
    "        print(\"Output size: {}\".format(self.output_size))\n",
    "\n",
    "    def append(self, sample_id, gui, img, to_show=False):\n",
    "        if to_show:\n",
    "            pic = img * 255\n",
    "            pic = np.array(pic, dtype=np.uint8)\n",
    "            Utils.show(pic)\n",
    "\n",
    "        token_sequence = [START_TOKEN]\n",
    "        for line in gui:\n",
    "            line = line.replace(\",\", \" ,\").replace(\"\\n\", \" \\n\")\n",
    "            tokens = line.split(\" \")\n",
    "            for token in tokens:\n",
    "                token_sequence.append(token)\n",
    "        token_sequence.append(END_TOKEN)\n",
    "        token_sequence = clean_sequence(token_sequence)\n",
    "        token_sequence = restore_sequence(token_sequence)\n",
    "        for token in token_sequence:\n",
    "            self.voc.append(token)\n",
    "        \n",
    "        self.ids.append(sample_id)\n",
    "        self.input_images.append(img)\n",
    "        self.total_sequences.append(token_sequence)\n",
    "\n",
    "    @staticmethod\n",
    "    def indexify(partial_sequences, voc):\n",
    "        temp = []\n",
    "        for sequence in partial_sequences:\n",
    "            sparse_vectors_sequence = []\n",
    "            for token in sequence:\n",
    "                sparse_vectors_sequence.append(voc.vocabulary[token])\n",
    "            temp.append(np.array(sparse_vectors_sequence))\n",
    "\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Generating sparse vectors...\n",
      "Dataset size: 1500\n",
      "Vocabulary size: 19\n",
      "Input shape: (256, 256, 3)\n",
      "Output size: 19\n"
     ]
    }
   ],
   "source": [
    "# Load caption annotation files and image files in Dataset\n",
    "raw_dataset = Dataset()\n",
    "raw_dataset.load(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<START>': 0, '<END>': 1, 'stack': 2, '{': 3, '\\n': 4, 'row': 5, 'label': 6, ',': 7, 'btn': 8, '}': 9, 'slider': 10, 'footer': 11, 'btn-notifications': 12, 'switch': 13, 'btn-dashboard': 14, 'btn-search': 15, 'radio': 16, 'check': 17, 'btn-home': 18}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset.voc.retrieve(output_path)\n",
    "raw_dataset.voc.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  4,  5,  3,  4,  6,  7,  8,  4,  9,  4,  5,  3,  4,  6,\n",
       "        7, 10,  7,  6,  4,  9,  4,  9,  4, 11,  3,  4, 12,  7, 12,  4,  9,\n",
       "        4,  1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset.total_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'72F3A88C-03C1-4321-A749-DC8CED488D4C'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset.ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<START>stack{\\nrow{\\nlabel,btn\\n}\\nrow{\\nlabel,slider,label\\n}\\n}\\nfooter{\\nbtn-notifications,btn-notifications\\n}\\n<END>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = ''\n",
    "predicted_sequence = raw_dataset.total_sequences[0]\n",
    "for k in range(0, len(predicted_sequence)):\n",
    "    prediction = predicted_sequence[k]\n",
    "    predictions += raw_dataset.voc.token_lookup[prediction]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../datasets/android/eval_set'\n",
    "file_name = 'TEST'\n",
    "with open(\"{}/{}.gui\".format(output_path, file_name), 'w') as out_f:\n",
    "    out_f.write(predictions.replace(START_TOKEN, \"\").replace(END_TOKEN, \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
